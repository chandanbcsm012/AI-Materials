# -*- coding: utf-8 -*-
"""28_June_Multi_Classification_loss_funs.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1K-zBRd_gdQqzK3nPpMZan97shdqFsN80
"""

import pandas as pd
import tensorflow as tf
from sklearn.metrics import accuracy_score

df=pd.read_csv('sample_data/mnist_train_small.csv',header=None)
X=df.iloc[:,1:].values
y=df.iloc[:,0].values

def output_neuron(X,w,b):
  return tf.matmul(X,w)+b

def loss(y_true,logits):
  return tf.reduce_mean(tf.losses.sparse_categorical_crossentropy(y_true,logits))

def activation(ynet):
  return tf.nn.softmax(ynet)

tf.random.set_seed(10)

wo=tf.Variable(tf.random.truncated_normal(shape=[784,10],dtype=tf.double))
bo=tf.Variable(tf.random.truncated_normal(shape=[10],dtype=tf.double))

from sklearn.preprocessing import StandardScaler
sc=StandardScaler()
X=df.iloc[:,1:].values
y=df.iloc[:,0].values
X_new=sc.fit_transform(X)
optimizer=tf.optimizers.SGD(learning_rate=.1)
for epoch in range(3000):
  with tf.GradientTape() as tape:
    ynet=output_neuron(X_new,wo,bo)
    logits=activation(ynet)
    ls=loss(y,logits)
    yhat=tf.argmax(logits,1)
    if(epoch%100==0):
      print(ls,accuracy_score(y,yhat))
    gradients=tape.gradient(ls,[wo,bo])
    optimizer.apply_gradients(zip(gradients,[wo,bo]))

df=pd.read_csv('sample_data/mnist_train_small.csv',header=None)
X=df.iloc[:,1:].values
y=df.iloc[:,0].values

def output_neuron(X,w,b):
  return tf.matmul(X,w)+b

def loss(y_true,logits):
  return tf.reduce_mean(tf.losses.categorical_crossentropy(y_true,logits))

def activation(ynet):
  return tf.nn.softmax(ynet)

tf.random.set_seed(10)

wo=tf.Variable(tf.random.truncated_normal(shape=[784,10],dtype=tf.double))
bo=tf.Variable(tf.random.truncated_normal(shape=[10],dtype=tf.double))

from sklearn.preprocessing import StandardScaler
sc=StandardScaler()
X=df.iloc[:,1:].values
y=df.iloc[:,0].values
X_new=sc.fit_transform(X)
optimizer=tf.optimizers.SGD(learning_rate=.1)
for epoch in range(5000):
  with tf.GradientTape() as tape:
    ynet=output_neuron(X_new,wo,bo)
    logits=activation(ynet)
    ls=loss(tf.one_hot(y,10),logits)
    yhat=tf.argmax(logits,1)
    if(epoch%500==0):
      print(ls,accuracy_score(y,yhat))
    gradients=tape.gradient(ls,[wo,bo])
    optimizer.apply_gradients(zip(gradients,[wo,bo]))

df_test=pd.read_csv('sample_data/mnist_test.csv',header=None)
df_test.shape

X_test=df_test.iloc[:,1:].values
y_test=df_test.iloc[:,0].values
X_test_new=sc.transform(X_test)
ynet=output_neuron(X_test_new,wo,bo)
logits=activation(ynet)
ls=loss(tf.one_hot(y_test,10),logits)
yhat=tf.argmax(logits,1)
print("Loss:",ls,'\t',"Score:",accuracy_score(y_test,yhat))

import cv2
gray=cv2.imread('7.png',0)
gray=gray.reshape(1,-1)
gray=sc.transform(gray)
ynet=output_neuron(gray,wo,bo)
logits=activation(ynet)
pred=tf.argmax(logits,1)
print(pred)

