{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist=fetch_openml(\"mnist_784\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def output_neuron(X,w,b):\n",
    "  return tf.matmul(X,w)+b\n",
    "\n",
    "def loss(y_true,logits):\n",
    "  return tf.reduce_mean(tf.losses.sparse_categorical_crossentropy(y_true,logits))\n",
    "\n",
    "def activation_hidden(ynet):\n",
    "  return tf.nn.tanh(ynet)\n",
    "\n",
    "def activation_output(ynet):\n",
    "  return tf.nn.relu(ynet)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \t loss: 8.775802874613944 \t Score: 11.5790476190%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-7e574d5ea2d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     \u001b[0mynet\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_neuron\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_new\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwh1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbh1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m     \u001b[0mlogits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mactivation_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mynet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-84-2d5dfcd7d2de>\u001b[0m in \u001b[0;36moutput_neuron\u001b[1;34m(X, w, b)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0moutput_neuron\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse_categorical_crossentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[1;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[0;32m   2982\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2983\u001b[0m       return gen_math_ops.mat_mul(\n\u001b[1;32m-> 2984\u001b[1;33m           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[0;32m   2985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[1;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[0;32m   5565\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"MatMul\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5566\u001b[0m         \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop_callbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"transpose_a\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"transpose_b\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5567\u001b[1;33m         transpose_b)\n\u001b[0m\u001b[0;32m   5568\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5569\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X,y=mnist['data'],mnist['target']\n",
    "# convert y in int\n",
    "y = [int(y) for y in y]\n",
    "y=np.array([y]).reshape(70000,1)\n",
    "\n",
    "\n",
    "\n",
    "                # tunning portion\n",
    "#####################################################        \n",
    "iteration=2000     # no of epoch                    #\n",
    "l_r=0.1            # learning rate                  #\n",
    "n_input = 784      # input layer (28x28 pixels)     #\n",
    "n_hidden1 = 512    # 1st hidden layer               #\n",
    "n_hidden2 = 256    # 2nd hidden layer               #\n",
    "n_hidden3 = 128    # 3rd hidden layer               #\n",
    "n_output = 10      # output layer (0-9 digits)      #                                           #\n",
    "#####################################################\n",
    "\n",
    "tf.random.set_seed(10)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=10)\n",
    "\n",
    "\n",
    "wh1=tf.Variable(tf.random.truncated_normal([n_input, n_hidden1],dtype=tf.double))\n",
    "bh1=tf.Variable(tf.constant(0.1, shape=[n_hidden1],dtype=tf.double))\n",
    "\n",
    "wh2=tf.Variable(tf.random.truncated_normal([n_hidden1, n_hidden2],dtype=tf.double))\n",
    "bh2=tf.Variable(tf.constant(0.1, shape=[n_hidden2],dtype=tf.double))\n",
    "\n",
    "\n",
    "wh3=tf.Variable(tf.random.truncated_normal([n_hidden2, n_hidden3],dtype=tf.double))\n",
    "bh3=tf.Variable(tf.constant(0.1, shape=[n_hidden3],dtype=tf.double))\n",
    "\n",
    "\n",
    "wo=tf.Variable(tf.random.truncated_normal([n_hidden3, n_output],dtype=tf.double))\n",
    "bo=tf.Variable(tf.constant(0.1, shape=[n_output],dtype=tf.double))\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "\n",
    "X_new=sc.fit_transform(X_train)\n",
    "\n",
    "optimizer=tf.optimizers.SGD(learning_rate=l_r)\n",
    "for epoch in range(iteration):\n",
    "    \n",
    "  with tf.GradientTape() as tape:\n",
    "    ynet=output_neuron(X_new,wh1,bh1)\n",
    "    logits=activation_hidden(ynet)\n",
    "\n",
    "    ynet=output_neuron(logits,wh2,bh2)\n",
    "    logits=activation_hidden(ynet)\n",
    "\n",
    "    ynet=output_neuron(logits,wh3,bh3)\n",
    "    logits=activation_hidden(ynet)    \n",
    "\n",
    "    ynet=output_neuron(logits,wo,bo)\n",
    "    logits=activation_output(ynet)\n",
    "\n",
    "    ls=loss(y_train,logits)\n",
    "    yhat=tf.argmax(logits,1)\n",
    "    if(epoch%10==0):\n",
    "        print(epoch+1,\"\\t loss:\",ls.numpy(),\"\\t Score:\",\"{:.10%}\".format(accuracy_score(y_train,yhat.numpy())))\n",
    "    gradients=tape.gradient(ls,[wo,bo,wh3,bh3,wh2,bh2,wh1,bh1])\n",
    "    optimizer.apply_gradients(zip(gradients,[wo,bo,wh3,bh3,wh2,bh2,wh1,bh1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.10045714285714286\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_test=sc.transform(X_test)\n",
    "\n",
    "ynet=output_neuron(X_test,wh1,bh1)\n",
    "logits=activation_hidden(ynet)\n",
    "\n",
    "ynet=output_neuron(logits,wh2,bh2)\n",
    "logits=activation_hidden(ynet)\n",
    "\n",
    "ynet=output_neuron(logits,wh3,bh3)\n",
    "logits=activation_hidden(ynet)\n",
    "\n",
    "ynet=output_neuron(logits,wo,bo)\n",
    "logits=activation_output(ynet)\n",
    "\n",
    "\n",
    "yhat=tf.argmax(logits,1)\n",
    "\n",
    "\n",
    "print('score:',accuracy_score(y_test,yhat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17500, 784)\n",
      "(784, 10)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "print(w.shape)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1], shape=(1,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "gray=cv2.imread('11.png',0)\n",
    "gray=gray.reshape(1,-1)\n",
    "gray=sc.transform(gray)\n",
    "\n",
    "\n",
    "\n",
    "ynet=output_neuron(gray,wh1,bh1)\n",
    "logits=activation_hidden(ynet)\n",
    "\n",
    "ynet=output_neuron(logits,wh2,bh2)\n",
    "logits=activation_hidden(ynet)\n",
    "\n",
    "\n",
    "ynet=output_neuron(logits,wh3,bh3)\n",
    "logits=activation_hidden(ynet)\n",
    "\n",
    "ynet=output_neuron(logits,wo,bo)\n",
    "logits=activation_output(ynet)\n",
    "\n",
    "\n",
    "pred=tf.argmax(logits,1)\n",
    "print(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
