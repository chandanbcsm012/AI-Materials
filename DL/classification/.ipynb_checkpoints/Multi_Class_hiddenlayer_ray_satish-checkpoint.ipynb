{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "28JuneMulti Class_hiddenlayer_Self.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLhzYAJAjzaR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4c77190a-db59-4ab6-c3f3-48112d9d801a"
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc=StandardScaler()\n",
        "df=pd.read_csv('/content/sample_data/mnist_train_small.csv',header=None)\n",
        "print(df.shape)\n",
        "#df.head(5)\n",
        "X=df.iloc[:,1:].values\n",
        "y=df.iloc[:,0].values\n",
        "X_new=sc.fit_transform(X)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20000, 785)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewZiDGj5Bcu-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "105f1565-e131-4a2b-84dd-bfbdfa2d1dbe"
      },
      "source": [
        "#Method 1:- Multi Class with 2 hidden layer for Mnist dataset\n",
        "def output_neuron(X,w,b):\n",
        "  return tf.matmul(X,w)+b\n",
        "\n",
        "def loss(y_true,logits):\n",
        "  return tf.reduce_mean(tf.losses.sparse_categorical_crossentropy(y_true,logits))\n",
        "\n",
        "def activation_hidden(ynet):\n",
        "  return tf.nn.tanh(ynet)\n",
        "\n",
        "def activation_output(ynet):\n",
        "  return tf.nn.softmax(ynet)\n",
        "\n",
        "tf.random.set_seed(10)\n",
        "\n",
        "wh1=tf.Variable(tf.random.truncated_normal(shape=[X_new.shape[1],300],dtype=tf.double))\n",
        "bh1=tf.Variable(tf.random.truncated_normal(shape=[300],dtype=tf.double))\n",
        "\n",
        "wh2=tf.Variable(tf.random.truncated_normal(shape=[300,150],dtype=tf.double))\n",
        "bh2=tf.Variable(tf.random.truncated_normal(shape=[150],dtype=tf.double))\n",
        "\n",
        "wo=tf.Variable(tf.random.truncated_normal(shape=[150,10],dtype=tf.double))\n",
        "bo=tf.Variable(tf.random.truncated_normal(shape=[10],dtype=tf.double))\n",
        "\n",
        "optimizer=tf.optimizers.SGD(learning_rate=.1)\n",
        "for epoch in range(5000):\n",
        "  with tf.GradientTape() as tape:\n",
        "\n",
        "    ynet=output_neuron(X_new,wh1,bh1)\n",
        "    logits=activation_hidden(ynet)\n",
        "\n",
        "    ynet=output_neuron(logits,wh2,bh2)\n",
        "    logits=activation_hidden(ynet)\n",
        "\n",
        "    ynet=output_neuron(logits,wo,bo)\n",
        "    logits=activation_output(ynet)\n",
        "    yhat=tf.argmax(logits,1) \n",
        "\n",
        "    ls=loss(y,logits)\n",
        "\n",
        "    if (epoch%500==0):\n",
        "      print(\"Loss: \",ls,\"\\t\",\"Score: \",accuracy_score(y,yhat))\n",
        "    gradients=tape.gradient(ls,[wh1,bh2,wh2,bh2,wo,bo])\n",
        "    optimizer.apply_gradients(zip(gradients,[wh1,bh2,wh2,bh2,wo,bo]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss:  tf.Tensor(11.298747997767903, shape=(), dtype=float64) \t Score:  0.1105\n",
            "Loss:  tf.Tensor(1.4463496150202104, shape=(), dtype=float64) \t Score:  0.8498\n",
            "Loss:  tf.Tensor(0.944052902871857, shape=(), dtype=float64) \t Score:  0.912\n",
            "Loss:  tf.Tensor(0.7528961498405886, shape=(), dtype=float64) \t Score:  0.9348\n",
            "Loss:  tf.Tensor(0.6707683842279641, shape=(), dtype=float64) \t Score:  0.94675\n",
            "Loss:  tf.Tensor(0.6168583473237103, shape=(), dtype=float64) \t Score:  0.9528\n",
            "Loss:  tf.Tensor(0.584234548511801, shape=(), dtype=float64) \t Score:  0.9581\n",
            "Loss:  tf.Tensor(0.5617652034590468, shape=(), dtype=float64) \t Score:  0.9608\n",
            "Loss:  tf.Tensor(0.5453011862179981, shape=(), dtype=float64) \t Score:  0.9622\n",
            "Loss:  tf.Tensor(0.5326879226645452, shape=(), dtype=float64) \t Score:  0.96405\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4aHoYy4ZYDz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "621f32a1-dc1b-41df-d56d-5f5f799aedab"
      },
      "source": [
        "# Method 2: Testing of Model\n",
        "df_test=pd.read_csv('/content/sample_data/mnist_test.csv',header=None)\n",
        "X_test=df_test.iloc[:,1:].values\n",
        "y_test=df_test.iloc[:,0].values\n",
        "X_test_new=sc.transform(X_test)\n",
        "\n",
        "ynet=output_neuron(X_test_new,wh1,bh1)\n",
        "logits=activation_hidden(ynet)\n",
        "\n",
        "ynet=output_neuron(logits,wh2,bh2)\n",
        "logits=activation_hidden(ynet)\n",
        "\n",
        "ynet=output_neuron(logits,wo,bo)\n",
        "logits=activation_output(ynet)\n",
        "\n",
        "yhat=tf.argmax(logits,1)\n",
        "\n",
        "ls=loss(y_test,logits)\n",
        "\n",
        "print(\"Loss: \",ls,\"\\t\",\"Score: \",accuracy_score(y_test,yhat.numpy()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss:  tf.Tensor(1.0238842426533743, shape=(), dtype=float64) \t Score:  0.7186\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxHLwOzpZ52U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "aa8f6980-f605-49ca-8ec0-183ffdea279e"
      },
      "source": [
        "# testing of sampleimage created by me\n",
        "import cv2\n",
        "gray=cv2.imread('5.png',0)\n",
        "print(gray.shape)\n",
        "gray=gray.reshape(1,-1)\n",
        "print(gray.shape)\n",
        "gray=sc.transform(gray)\n",
        "ynet=output_neuron(gray,wh1,bh1)\n",
        "logits=activation_hidden(ynet)\n",
        "\n",
        "ynet=output_neuron(logits,wh2,bh2)\n",
        "logits=activation_hidden(ynet)\n",
        "\n",
        "ynet=output_neuron(logits,wo,bo)\n",
        "logits=activation_output(ynet)\n",
        "\n",
        "pred=tf.argmax(logits,1)\n",
        "print(pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28, 28)\n",
            "(1, 784)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-f51943c78adc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgray\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mgray\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mynet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_neuron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwh1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbh1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mactivation_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mynet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'sc' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiWFs3JYoO8w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "d3e61440-7011-46ca-f853-16fde4f8996e"
      },
      "source": [
        "#Method 3:- Multi Class with 1 hidden layer for Mnist dataset\n",
        "def output_neuron(X,w,b):\n",
        "  return tf.matmul(X,w)+b\n",
        "\n",
        "def loss(y_true,logits):\n",
        "  return tf.reduce_mean(tf.losses.sparse_categorical_crossentropy(y_true,logits))\n",
        "\n",
        "def activation_hidden(ynet):\n",
        "  return tf.nn.sigmoid(ynet)\n",
        "\n",
        "def activation_output(ynet):\n",
        "  return tf.nn.softmax(ynet)\n",
        "\n",
        "tf.random.set_seed(10)\n",
        "\n",
        "wh1=tf.Variable(tf.random.truncated_normal(shape=[X_new.shape[1],300],dtype=tf.double))\n",
        "bh1=tf.Variable(tf.random.truncated_normal(shape=[300],dtype=tf.double))\n",
        "\n",
        "wh2=tf.Variable(tf.random.truncated_normal(shape=[300,150],dtype=tf.double))\n",
        "bh2=tf.Variable(tf.random.truncated_normal(shape=[150],dtype=tf.double))\n",
        "\n",
        "wo=tf.Variable(tf.random.truncated_normal(shape=[150,10],dtype=tf.double))\n",
        "bo=tf.Variable(tf.random.truncated_normal(shape=[10],dtype=tf.double))\n",
        "\n",
        "optimizer=tf.optimizers.SGD(learning_rate=.1)\n",
        "for epoch in range(5000):\n",
        "  with tf.GradientTape() as tape:\n",
        "\n",
        "    ynet=output_neuron(X_new,wh1,bh1)\n",
        "    logits=activation_hidden(ynet)\n",
        "\n",
        "    ynet=output_neuron(logits,wh2,bh2)\n",
        "    logits=activation_hidden(ynet)\n",
        "\n",
        "    ynet=output_neuron(logits,wo,bo)\n",
        "    logits=activation_output(ynet)\n",
        "    yhat=tf.argmax(logits,1) \n",
        "\n",
        "    ls=loss(y,logits)\n",
        "\n",
        "    if (epoch%500==0):\n",
        "      print(\"Loss: \",ls,\"\\t\",\"Score: \",accuracy_score(y,yhat))\n",
        "    gradients=tape.gradient(ls,[wh1,bh2,wh2,bh2,wo,bo])\n",
        "    optimizer.apply_gradients(zip(gradients,[wh1,bh2,wh2,bh2,wo,bo]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss:  tf.Tensor(10.463310019415209, shape=(), dtype=float64) \t Score:  0.09495\n",
            "Loss:  tf.Tensor(0.9394924648628769, shape=(), dtype=float64) \t Score:  0.73425\n",
            "Loss:  tf.Tensor(0.6003191347792013, shape=(), dtype=float64) \t Score:  0.82435\n",
            "Loss:  tf.Tensor(0.4545164194916901, shape=(), dtype=float64) \t Score:  0.8663\n",
            "Loss:  tf.Tensor(0.36810595299497884, shape=(), dtype=float64) \t Score:  0.8939\n",
            "Loss:  tf.Tensor(0.3093495641683712, shape=(), dtype=float64) \t Score:  0.9128\n",
            "Loss:  tf.Tensor(0.2660118451229839, shape=(), dtype=float64) \t Score:  0.92725\n",
            "Loss:  tf.Tensor(0.2326301280694543, shape=(), dtype=float64) \t Score:  0.9393\n",
            "Loss:  tf.Tensor(0.20583577101305742, shape=(), dtype=float64) \t Score:  0.9481\n",
            "Loss:  tf.Tensor(0.18372787041434258, shape=(), dtype=float64) \t Score:  0.9554\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0_2veID_Yfa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "c2a2e675-ebbe-4da7-e406-357aff35ceb7"
      },
      "source": [
        "# Method 2: Testing of Model with Sigmoid\n",
        "df_test=pd.read_csv('/content/sample_data/mnist_test.csv',header=None)\n",
        "X_test=df_test.iloc[:,1:].values\n",
        "y_test=df_test.iloc[:,0].values\n",
        "X_test_new=sc.transform(X_test)\n",
        "\n",
        "ynet=output_neuron(X_test_new,wh1,bh1)\n",
        "logits=activation_hidden(ynet)\n",
        "\n",
        "ynet=output_neuron(logits,wh2,bh2)\n",
        "logits=activation_hidden(ynet)\n",
        "\n",
        "ynet=output_neuron(logits,wo,bo)\n",
        "logits=activation_output(ynet)\n",
        "\n",
        "yhat=tf.argmax(logits,1)\n",
        "\n",
        "ls=loss(y_test,logits)\n",
        "\n",
        "print(\"Loss: \",ls,\"\\t\",\"Score: \",accuracy_score(y_test,yhat.numpy()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-74d6706205c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Method 2: Testing of Model with Sigmoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/sample_data/mnist_test.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_test_new\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJgCXJRH_o8_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "cd153063-df0b-4dac-a467-86e04668bb27"
      },
      "source": [
        "#Method 3:- Multi Class with 2 hidden layer with Sigmoid and tanh for Mnist dataset\n",
        "def output_neuron(X,w,b):\n",
        "  return tf.matmul(X,w)+b\n",
        "\n",
        "def loss(y_true,logits):\n",
        "  return tf.reduce_mean(tf.losses.sparse_categorical_crossentropy(y_true,logits))\n",
        "\n",
        "def activation_hidden1(ynet):\n",
        "  return tf.nn.sigmoid(ynet)\n",
        "\n",
        "def activation_hidden2(ynet):\n",
        "  return tf.nn.tanh(ynet)\n",
        "\n",
        "def activation_output(ynet):\n",
        "  return tf.nn.softmax(ynet)\n",
        "\n",
        "tf.random.set_seed(10)\n",
        "\n",
        "wh1=tf.Variable(tf.random.truncated_normal(shape=[X_new.shape[1],300],dtype=tf.double))\n",
        "bh1=tf.Variable(tf.random.truncated_normal(shape=[300],dtype=tf.double))\n",
        "\n",
        "wh2=tf.Variable(tf.random.truncated_normal(shape=[300,150],dtype=tf.double))\n",
        "bh2=tf.Variable(tf.random.truncated_normal(shape=[150],dtype=tf.double))\n",
        "\n",
        "wo=tf.Variable(tf.random.truncated_normal(shape=[150,10],dtype=tf.double))\n",
        "bo=tf.Variable(tf.random.truncated_normal(shape=[10],dtype=tf.double))\n",
        "\n",
        "optimizer=tf.optimizers.SGD(learning_rate=.1)\n",
        "for epoch in range(5000):\n",
        "  with tf.GradientTape() as tape:\n",
        "\n",
        "    ynet=output_neuron(X_new,wh1,bh1)\n",
        "    logits=activation_hidden1(ynet)\n",
        "\n",
        "    ynet=output_neuron(logits,wh2,bh2)\n",
        "    logits=activation_hidden2(ynet)\n",
        "\n",
        "    ynet=output_neuron(logits,wo,bo)\n",
        "    logits=activation_output(ynet)\n",
        "    yhat=tf.argmax(logits,1) \n",
        "\n",
        "    ls=loss(y,logits)\n",
        "\n",
        "    if (epoch%500==0):\n",
        "      print(\"Loss: \",ls,\"\\t\",\"Score: \",accuracy_score(y,yhat))\n",
        "    gradients=tape.gradient(ls,[wh1,bh2,wh2,bh2,wo,bo])\n",
        "    optimizer.apply_gradients(zip(gradients,[wh1,bh2,wh2,bh2,wo,bo]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss:  tf.Tensor(11.361427979411236, shape=(), dtype=float64) \t Score:  0.102\n",
            "Loss:  tf.Tensor(0.9893399989563797, shape=(), dtype=float64) \t Score:  0.82585\n",
            "Loss:  tf.Tensor(0.5459954532224186, shape=(), dtype=float64) \t Score:  0.90705\n",
            "Loss:  tf.Tensor(0.38482239360382325, shape=(), dtype=float64) \t Score:  0.93895\n",
            "Loss:  tf.Tensor(0.30584753412934595, shape=(), dtype=float64) \t Score:  0.9558\n",
            "Loss:  tf.Tensor(0.2563893991795791, shape=(), dtype=float64) \t Score:  0.96595\n",
            "Loss:  tf.Tensor(0.2229526789026424, shape=(), dtype=float64) \t Score:  0.9716\n",
            "Loss:  tf.Tensor(0.1970931956875662, shape=(), dtype=float64) \t Score:  0.97725\n",
            "Loss:  tf.Tensor(0.17866981943039836, shape=(), dtype=float64) \t Score:  0.98055\n",
            "Loss:  tf.Tensor(0.1648232053692876, shape=(), dtype=float64) \t Score:  0.98355\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1k6sI1n0W4q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7ce4fcbb-7d08-4caa-88bb-421f14ea9440"
      },
      "source": [
        "# Method 3 Test: Testing of Model with Sigmoid and tanh\n",
        "df_test=pd.read_csv('/content/sample_data/mnist_test.csv',header=None)\n",
        "X_test=df_test.iloc[:,1:].values\n",
        "y_test=df_test.iloc[:,0].values\n",
        "X_test_new=sc.transform(X_test)\n",
        "\n",
        "ynet=output_neuron(X_test_new,wh1,bh1)\n",
        "logits=activation_hidden1(ynet)\n",
        "\n",
        "ynet=output_neuron(logits,wh2,bh2)\n",
        "logits=activation_hidden2(ynet)\n",
        "\n",
        "ynet=output_neuron(logits,wo,bo)\n",
        "logits=activation_output(ynet)\n",
        "\n",
        "yhat=tf.argmax(logits,1)\n",
        "\n",
        "ls=loss(y_test,logits)\n",
        "\n",
        "print(\"Loss: \",ls,\"\\t\",\"Score: \",accuracy_score(y_test,yhat.numpy()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss:  tf.Tensor(1.3016096045411982, shape=(), dtype=float64) \t Score:  0.7815\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0T-N8_2Q0tBk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "a35eb602-6358-480c-a9e0-b30b1e05daf5"
      },
      "source": [
        "#Method 4:- Multi Class with 2 hidden layer with Sigmoid and tanh for Mnist dataset but diff leraning rate\n",
        "def output_neuron(X,w,b):\n",
        "  return tf.matmul(X,w)+b\n",
        "\n",
        "def loss(y_true,logits):\n",
        "  return tf.reduce_mean(tf.losses.sparse_categorical_crossentropy(y_true,logits))\n",
        "\n",
        "def activation_hidden1(ynet):\n",
        "  return tf.nn.sigmoid(ynet)\n",
        "\n",
        "def activation_hidden2(ynet):\n",
        "  return tf.nn.tanh(ynet)\n",
        "\n",
        "def activation_output(ynet):\n",
        "  return tf.nn.softmax(ynet)\n",
        "\n",
        "tf.random.set_seed(10)\n",
        "\n",
        "wh1=tf.Variable(tf.random.truncated_normal(shape=[X_new.shape[1],100],dtype=tf.double))\n",
        "bh1=tf.Variable(tf.random.truncated_normal(shape=[100],dtype=tf.double))\n",
        "\n",
        "wh2=tf.Variable(tf.random.truncated_normal(shape=[100,50],dtype=tf.double))\n",
        "bh2=tf.Variable(tf.random.truncated_normal(shape=[50],dtype=tf.double))\n",
        "\n",
        "wo=tf.Variable(tf.random.truncated_normal(shape=[50,10],dtype=tf.double))\n",
        "bo=tf.Variable(tf.random.truncated_normal(shape=[10],dtype=tf.double))\n",
        "\n",
        "optimizer=tf.optimizers.SGD(learning_rate=.1)\n",
        "for epoch in range(5000):\n",
        "  with tf.GradientTape() as tape:\n",
        "\n",
        "    ynet=output_neuron(X_new,wh1,bh1)\n",
        "    logits=activation_hidden1(ynet)\n",
        "\n",
        "    ynet=output_neuron(logits,wh2,bh2)\n",
        "    logits=activation_hidden2(ynet)\n",
        "\n",
        "    ynet=output_neuron(logits,wo,bo)\n",
        "    logits=activation_output(ynet)\n",
        "    yhat=tf.argmax(logits,1) \n",
        "\n",
        "    ls=loss(y,logits)\n",
        "\n",
        "    if (epoch%500==0):\n",
        "      print(\"Loss: \",ls,\"\\t\",\"Score: \",accuracy_score(y,yhat))\n",
        "    gradients=tape.gradient(ls,[wh1,bh2,wh2,bh2,wo,bo])\n",
        "    optimizer.apply_gradients(zip(gradients,[wh1,bh2,wh2,bh2,wo,bo]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss:  tf.Tensor(9.943732629862614, shape=(), dtype=float64) \t Score:  0.08875\n",
            "Loss:  tf.Tensor(1.0883084803625813, shape=(), dtype=float64) \t Score:  0.6702\n",
            "Loss:  tf.Tensor(0.7696970059199562, shape=(), dtype=float64) \t Score:  0.75295\n",
            "Loss:  tf.Tensor(0.6334153762526623, shape=(), dtype=float64) \t Score:  0.79545\n",
            "Loss:  tf.Tensor(0.5495838646009208, shape=(), dtype=float64) \t Score:  0.82575\n",
            "Loss:  tf.Tensor(0.48883303999485506, shape=(), dtype=float64) \t Score:  0.84635\n",
            "Loss:  tf.Tensor(0.4426326785819836, shape=(), dtype=float64) \t Score:  0.8607\n",
            "Loss:  tf.Tensor(0.40485504517090337, shape=(), dtype=float64) \t Score:  0.873\n",
            "Loss:  tf.Tensor(0.37313232286434767, shape=(), dtype=float64) \t Score:  0.8846\n",
            "Loss:  tf.Tensor(0.3456205532921935, shape=(), dtype=float64) \t Score:  0.89525\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpfhcXvyFUHt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "08eb76a5-f146-49f1-b498-ddcc4bb44629"
      },
      "source": [
        "# Method 3 Test: Testing of Model with Sigmoid and tanh\n",
        "df_test=pd.read_csv('/content/sample_data/mnist_test.csv',header=None)\n",
        "X_test=df_test.iloc[:,1:].values\n",
        "y_test=df_test.iloc[:,0].values\n",
        "X_test_new=sc.transform(X_test)\n",
        "\n",
        "ynet=output_neuron(X_test_new,wh1,bh1)\n",
        "logits=activation_hidden1(ynet)\n",
        "\n",
        "ynet=output_neuron(logits,wh2,bh2)\n",
        "logits=activation_hidden2(ynet)\n",
        "\n",
        "ynet=output_neuron(logits,wo,bo)\n",
        "logits=activation_output(ynet)\n",
        "\n",
        "yhat=tf.argmax(logits,1)\n",
        "\n",
        "ls=loss(y_test,logits)\n",
        "\n",
        "print(\"Loss: \",ls,\"\\t\",\"Score: \",accuracy_score(y_test,yhat.numpy()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss:  tf.Tensor(0.6812519057839175, shape=(), dtype=float64) \t Score:  0.8019\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}