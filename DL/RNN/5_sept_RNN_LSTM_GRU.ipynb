{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5_sept_RNN_LSTM_GRU.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuqW_jejpfuR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus=[\n",
        "\t\t    'food is very good',\n",
        "\t\t    'awesome food and nice quality',\n",
        "\t\t    'food is not good',\n",
        "\t\t    'poor quality no toppings'\n",
        "\t  ]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Zj2t1qSp4Yd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "41874ff5-e6c9-46bf-994f-dd3a5faab0e0"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "tk=Tokenizer()\n",
        "tk.fit_on_texts(corpus)\n",
        "print(tk.word_index)\n",
        "print(tk.index_word)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'food': 1, 'is': 2, 'good': 3, 'quality': 4, 'very': 5, 'awesome': 6, 'and': 7, 'nice': 8, 'not': 9, 'poor': 10, 'no': 11, 'toppings': 12}\n",
            "{1: 'food', 2: 'is', 3: 'good', 4: 'quality', 5: 'very', 6: 'awesome', 7: 'and', 8: 'nice', 9: 'not', 10: 'poor', 11: 'no', 12: 'toppings'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwRiftiYqGvj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "632a9755-6b8e-4578-e5d6-3c0a313a503b"
      },
      "source": [
        "seqes=tk.texts_to_sequences(corpus)\n",
        "print(seqes)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1, 2, 5, 3], [6, 1, 7, 8, 4], [1, 2, 9, 3], [10, 4, 11, 12]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbwwKBLZq6PW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEhWFebVrlNF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "c304357c-4604-4187-b1e3-6217d12188d1"
      },
      "source": [
        "pad_seqes=pad_sequences(seqes,padding='pre')\n",
        "pad_seqes.shape\n",
        "pad_seqes"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  1,  2,  5,  3],\n",
              "       [ 6,  1,  7,  8,  4],\n",
              "       [ 0,  1,  2,  9,  3],\n",
              "       [ 0, 10,  4, 11, 12]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lX5Ot9gMsGNh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "vocab_size=len(tk.word_index)\n",
        "word_dim=3\n",
        "seq_len=pad_seqes.shape[1]\n",
        "emd=Embedding(input_dim=vocab_size+1,output_dim=word_dim,input_length=seq_len)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MS6a7ig7t1Hn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_emd=emd(1) #returns word enbedding of word whose position is 1 in vocabulary"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zzMHIvEutts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "word_emd_seq=emd(np.array([ 0,  1,  2,  5,  3]))"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BssNLZiGvMoV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "263b3437-8263-48d4-e93c-9dcfedff4fe0"
      },
      "source": [
        "word_emd_seques=emd(pad_seqes)\n",
        "print(word_emd_seques.shape) #samples,seq_length,word_dimd\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4, 5, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWPkH20lx_Ok",
        "colab_type": "text"
      },
      "source": [
        "# How to combine word embedding using Embedding layer with RNN/LSTM/GRU "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6_OIJzhyqNO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import SimpleRNN,Dense,GlobalAveragePooling1D,LSTM,GRU\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKXbR8s9vvOQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "1cfd123d-a7c8-4483-dc3f-e1da8734ec83"
      },
      "source": [
        "corpus=[\n",
        "\t\t    'food is very good',\n",
        "\t\t    'awesome food and nice quality',\n",
        "\t\t    'food is not good',\n",
        "\t\t    'poor quality no toppings'\n",
        "\t  ]    \n",
        "\n",
        "y=np.array([1,1,0,0])\n",
        "\n",
        "tk=Tokenizer()\n",
        "tk.fit_on_texts(corpus)\n",
        "pad_seqes=pad_sequences(seqes,padding='pre')\n",
        "\n",
        "vocab_size=len(tk.word_index)\n",
        "word_dim=3\n",
        "seq_len=pad_seqes.shape[1]\n",
        "\n",
        "model=Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size+1,output_dim=word_dim,input_length=seq_len))\n",
        "#model.add(SimpleRNN(10,input_shape=(word_dim,seq_len),return_sequences=True))\n",
        "model.add(LSTM(10,input_shape=(word_dim,seq_len),return_sequences=True))\n",
        "model.add(GlobalAveragePooling1D())\n",
        "model.add(Dense(2,activation='softmax'))\n",
        "model.compile('adam','sparse_categorical_crossentropy',['accuracy'])\n",
        "model.fit(pad_seqes,y,epochs=5)\n",
        "\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6919 - accuracy: 0.7500\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6917 - accuracy: 0.5000\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5000\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5000\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe4e0035080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgy9YQNV1sNy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763
        },
        "outputId": "27e93c95-6db9-447f-d7c7-add01d6a4ce4"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "df=pd.read_csv(\"drive/My Drive/dataset_dl/sentiment/Restaurant_Reviews.txt\",sep='\\t')\n",
        "X=df.Review\n",
        "y=df.Liked\n",
        "\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=10)\n",
        "\n",
        "tk=Tokenizer()\n",
        "tk.fit_on_texts(X_train)\n",
        "\n",
        "seq_train=tk.texts_to_sequences(X_train)\n",
        "pad_seqes_train=pad_sequences(seq_train,padding='pre')\n",
        "\n",
        "vocab_size=len(tk.word_index)\n",
        "word_dim=50\n",
        "seq_len=pad_seqes_train.shape[1]\n",
        "\n",
        "seq_test=tk.texts_to_sequences(X_test)\n",
        "pad_seqes_test=pad_sequences(seq_test,padding='pre',truncating='pre',maxlen=seq_len)\n",
        "\n",
        "model=Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size+1,output_dim=word_dim,input_length=seq_len))\n",
        "#model.add(SimpleRNN(20,input_shape=(word_dim,seq_len),return_sequences=True))\n",
        "#model.add(LSTM(10,input_shape=(word_dim,seq_len),return_sequences=True))\n",
        "model.add(GRU(10,input_shape=(word_dim,seq_len),return_sequences=True))\n",
        "model.add(GlobalAveragePooling1D())\n",
        "model.add(Dense(10))\n",
        "model.add(Dense(2,activation='softmax'))\n",
        "model.compile('adam','sparse_categorical_crossentropy',['accuracy'])\n",
        "model.fit(pad_seqes_train,y_train,epochs=20)\n"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.6934 - accuracy: 0.5080\n",
            "Epoch 2/20\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.6851 - accuracy: 0.5480\n",
            "Epoch 3/20\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.6687 - accuracy: 0.6307\n",
            "Epoch 4/20\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.6177 - accuracy: 0.7813\n",
            "Epoch 5/20\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.5008 - accuracy: 0.8013\n",
            "Epoch 6/20\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.3608 - accuracy: 0.8627\n",
            "Epoch 7/20\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.2500 - accuracy: 0.9200\n",
            "Epoch 8/20\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.2013 - accuracy: 0.9253\n",
            "Epoch 9/20\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.1611 - accuracy: 0.9600\n",
            "Epoch 10/20\n",
            "24/24 [==============================] - 0s 11ms/step - loss: 0.1278 - accuracy: 0.9573\n",
            "Epoch 11/20\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.1097 - accuracy: 0.9680\n",
            "Epoch 12/20\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.1071 - accuracy: 0.9707\n",
            "Epoch 13/20\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.0758 - accuracy: 0.9893\n",
            "Epoch 14/20\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.0660 - accuracy: 0.9853\n",
            "Epoch 15/20\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.0634 - accuracy: 0.9893\n",
            "Epoch 16/20\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.0526 - accuracy: 0.9880\n",
            "Epoch 17/20\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.0448 - accuracy: 0.9920\n",
            "Epoch 18/20\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.0416 - accuracy: 0.9907\n",
            "Epoch 19/20\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.0408 - accuracy: 0.9947\n",
            "Epoch 20/20\n",
            "24/24 [==============================] - 0s 12ms/step - loss: 0.0320 - accuracy: 0.9947\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe4dd50b748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9G4gxfo1AJ5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "042febf6-3dd8-497f-ce77-fc162e77542c"
      },
      "source": [
        "model.evaluate(pad_seqes_test,y_test)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7820 - accuracy: 0.7360\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7820084691047668, 0.7360000014305115]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfOHecVX4I75",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "64147910-4d03-4378-e820-cb89fdd99e45"
      },
      "source": [
        "samples=['food quality is awesome','cheap quality','will not come again']\n",
        "seq_samples=tk.texts_to_sequences(samples)\n",
        "pad_seqes_samples=pad_sequences(seq_samples,padding='pre',truncating='pre',maxlen=seq_len)\n",
        "np.argmax(model.predict(pad_seqes_samples),axis=-1)\n"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "no2ZGVlT4uoF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}