{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('../../dataset/regression/salary_1_variable.csv')\n",
    "X=df.iloc[:,:-1].values\n",
    "y=df.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 12585.26, NNZs: 1, Bias: 1983.473599, T: 30, Avg. loss: 325557788.064943\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 12693.21, NNZs: 1, Bias: 2605.548935, T: 60, Avg. loss: 80757994.346439\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 12913.11, NNZs: 1, Bias: 3159.723968, T: 90, Avg. loss: 78067231.433204\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 13060.59, NNZs: 1, Bias: 3639.620921, T: 120, Avg. loss: 74559261.021576\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 12383.81, NNZs: 1, Bias: 3973.355972, T: 150, Avg. loss: 71894951.355158\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 12675.57, NNZs: 1, Bias: 4416.648941, T: 180, Avg. loss: 70759882.001694\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 12727.93, NNZs: 1, Bias: 4801.189876, T: 210, Avg. loss: 68614872.431954\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 12443.60, NNZs: 1, Bias: 5114.036590, T: 240, Avg. loss: 66674914.580079\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 12424.59, NNZs: 1, Bias: 5448.985715, T: 270, Avg. loss: 65017781.530001\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 12106.67, NNZs: 1, Bias: 5731.896375, T: 300, Avg. loss: 62389872.192019\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 12157.72, NNZs: 1, Bias: 6052.133350, T: 330, Avg. loss: 61437952.173421\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 12490.78, NNZs: 1, Bias: 6394.019841, T: 360, Avg. loss: 59105795.946073\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 12307.99, NNZs: 1, Bias: 6661.165575, T: 390, Avg. loss: 59980989.163033\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 12197.73, NNZs: 1, Bias: 6922.986299, T: 420, Avg. loss: 58177013.375457\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 12269.77, NNZs: 1, Bias: 7207.279801, T: 450, Avg. loss: 57012498.573268\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 12080.69, NNZs: 1, Bias: 7448.814780, T: 480, Avg. loss: 55546671.459815\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 12362.68, NNZs: 1, Bias: 7748.676955, T: 510, Avg. loss: 53265820.911275\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 12208.89, NNZs: 1, Bias: 7978.029362, T: 540, Avg. loss: 53640754.380921\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 11611.21, NNZs: 1, Bias: 8109.379335, T: 570, Avg. loss: 48500306.282592\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 11828.20, NNZs: 1, Bias: 8379.994694, T: 600, Avg. loss: 51843920.248629\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 11761.77, NNZs: 1, Bias: 8601.829633, T: 630, Avg. loss: 50296105.402074\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 11828.00, NNZs: 1, Bias: 8838.790271, T: 660, Avg. loss: 49013356.513040\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 11978.98, NNZs: 1, Bias: 9078.457195, T: 690, Avg. loss: 48397945.379625\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 11775.01, NNZs: 1, Bias: 9262.540142, T: 720, Avg. loss: 47906001.454508\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 12019.59, NNZs: 1, Bias: 9503.338415, T: 750, Avg. loss: 46403220.236895\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 11818.61, NNZs: 1, Bias: 9680.213499, T: 780, Avg. loss: 46463443.995131\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 11751.13, NNZs: 1, Bias: 9867.367817, T: 810, Avg. loss: 45797968.504839\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 11845.87, NNZs: 1, Bias: 10073.660083, T: 840, Avg. loss: 44426631.381766\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 11732.80, NNZs: 1, Bias: 10245.900381, T: 870, Avg. loss: 44286464.736310\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 11584.47, NNZs: 1, Bias: 10416.518751, T: 900, Avg. loss: 43248637.795677\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 11770.36, NNZs: 1, Bias: 10626.488427, T: 930, Avg. loss: 42134861.973053\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 11627.76, NNZs: 1, Bias: 10786.210427, T: 960, Avg. loss: 42435663.105807\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 11571.42, NNZs: 1, Bias: 10953.469473, T: 990, Avg. loss: 41805211.609313\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 11689.20, NNZs: 1, Bias: 11142.829981, T: 1020, Avg. loss: 40746473.530410\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 11620.04, NNZs: 1, Bias: 11303.540418, T: 1050, Avg. loss: 40670689.296177\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 11665.41, NNZs: 1, Bias: 11479.200784, T: 1080, Avg. loss: 39652538.067079\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 11563.16, NNZs: 1, Bias: 11629.840304, T: 1110, Avg. loss: 39681197.764274\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 11260.28, NNZs: 1, Bias: 11740.773109, T: 1140, Avg. loss: 37812663.089421\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 11452.78, NNZs: 1, Bias: 11929.529310, T: 1170, Avg. loss: 38600419.668413\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 11328.89, NNZs: 1, Bias: 12064.789853, T: 1200, Avg. loss: 37787147.098126\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 11346.26, NNZs: 1, Bias: 12222.611794, T: 1230, Avg. loss: 37322389.407337\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 11381.86, NNZs: 1, Bias: 12378.978905, T: 1260, Avg. loss: 36945882.675869\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 11250.87, NNZs: 1, Bias: 12508.769927, T: 1290, Avg. loss: 35962037.716310\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 11519.80, NNZs: 1, Bias: 12693.876019, T: 1320, Avg. loss: 35377479.200830\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 11467.56, NNZs: 1, Bias: 12828.644171, T: 1350, Avg. loss: 35650255.243563\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 11251.54, NNZs: 1, Bias: 12936.046625, T: 1380, Avg. loss: 34951937.835785\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 11326.58, NNZs: 1, Bias: 13084.592487, T: 1410, Avg. loss: 34850610.007325\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 11318.39, NNZs: 1, Bias: 13219.457627, T: 1440, Avg. loss: 34402581.499763\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 11286.83, NNZs: 1, Bias: 13350.903714, T: 1470, Avg. loss: 33967556.871927\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 11343.55, NNZs: 1, Bias: 13492.718180, T: 1500, Avg. loss: 33320953.862887\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 11220.51, NNZs: 1, Bias: 13605.802690, T: 1530, Avg. loss: 33369095.821139\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 11121.45, NNZs: 1, Bias: 13719.889620, T: 1560, Avg. loss: 32869039.253828\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 11194.06, NNZs: 1, Bias: 13856.176680, T: 1590, Avg. loss: 32649524.786561\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 11226.72, NNZs: 1, Bias: 13984.615017, T: 1620, Avg. loss: 32249178.417458\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 11339.40, NNZs: 1, Bias: 14122.180547, T: 1650, Avg. loss: 31423404.654069\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 11125.80, NNZs: 1, Bias: 14211.928530, T: 1680, Avg. loss: 31621915.414314\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 10902.21, NNZs: 1, Bias: 14294.048366, T: 1710, Avg. loss: 30226265.541639\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 11135.36, NNZs: 1, Bias: 14444.669335, T: 1740, Avg. loss: 31067798.028982\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 11068.18, NNZs: 1, Bias: 14548.859421, T: 1770, Avg. loss: 30729924.392328\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 11018.91, NNZs: 1, Bias: 14656.280080, T: 1800, Avg. loss: 30386911.157963\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 11040.08, NNZs: 1, Bias: 14772.215458, T: 1830, Avg. loss: 30237863.601406\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 10891.25, NNZs: 1, Bias: 14860.418956, T: 1860, Avg. loss: 29397153.062686\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 11105.94, NNZs: 1, Bias: 15000.863224, T: 1890, Avg. loss: 29460752.910509\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 11141.31, NNZs: 1, Bias: 15113.176846, T: 1920, Avg. loss: 29132055.688635\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 11033.18, NNZs: 1, Bias: 15199.393311, T: 1950, Avg. loss: 29054174.093999\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 10946.61, NNZs: 1, Bias: 15291.303923, T: 1980, Avg. loss: 28885064.990378\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 10944.07, NNZs: 1, Bias: 15391.907461, T: 2010, Avg. loss: 28529690.805766\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 10987.63, NNZs: 1, Bias: 15502.620095, T: 2040, Avg. loss: 28199074.172871\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 11099.05, NNZs: 1, Bias: 15620.259465, T: 2070, Avg. loss: 27615485.237175\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 10929.97, NNZs: 1, Bias: 15697.428058, T: 2100, Avg. loss: 28074673.980956\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 10848.78, NNZs: 1, Bias: 15783.873518, T: 2130, Avg. loss: 27650403.113068\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 10853.04, NNZs: 1, Bias: 15879.630431, T: 2160, Avg. loss: 27435543.079569\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 10856.52, NNZs: 1, Bias: 15976.785116, T: 2190, Avg. loss: 27301182.870319\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 11020.54, NNZs: 1, Bias: 16095.887998, T: 2220, Avg. loss: 26530278.777508\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 10918.71, NNZs: 1, Bias: 16173.983973, T: 2250, Avg. loss: 26945009.229967\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 10646.63, NNZs: 1, Bias: 16218.669036, T: 2280, Avg. loss: 25270829.501616\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 10799.57, NNZs: 1, Bias: 16332.030642, T: 2310, Avg. loss: 26606674.340372\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 10811.38, NNZs: 1, Bias: 16423.124449, T: 2340, Avg. loss: 26292718.274948\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 10817.81, NNZs: 1, Bias: 16514.056536, T: 2370, Avg. loss: 26061939.262948\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 10796.05, NNZs: 1, Bias: 16598.657486, T: 2400, Avg. loss: 25901965.429743\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 10669.17, NNZs: 1, Bias: 16665.243323, T: 2430, Avg. loss: 25421315.784858\n",
      "Total training time: 0.04 seconds.\n",
      "Convergence after 81 epochs took 0.04 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
       "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
       "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
       "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=None,\n",
       "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=True,\n",
       "             warm_start=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd=SGDRegressor(verbose=True)\n",
    "sgd.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron for Regression Manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def output_neuron(X,w,b):\n",
    "    yhat=X@w+b\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(yhat,ytrue):\n",
    "    return (np.sum(np.square(yhat-ytrue)))/2*len(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(X,ytrue,w,b,lr):\n",
    "    bias_derv=np.sum((X@w+b)-ytrue)/len(ytrue)\n",
    "    weight_derv=np.sum(((X@w+b)-ytrue)*X)/len(ytrue)\n",
    "    \n",
    "    new_bias=b-lr*bias_derv\n",
    "    new_weight=w-lr*weight_derv\n",
    "    return new_bias,new_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2926077402716.18\n",
      "initial parameters: [0.53895257] 0.30567393564733103\n",
      "2037989346751.441\n",
      "638786142263.7491\n",
      "635614160760.0088\n",
      "164761411531.95065\n",
      "263337553249.11765\n",
      "83801327189.76294\n",
      "155015647176.73053\n",
      "79442033492.49974\n",
      "119434285493.23494\n",
      "85502946115.4438\n",
      "106160904338.64311\n",
      "90354445178.89027\n",
      "100661138154.72087\n",
      "93153272692.12146\n",
      "98215439209.569\n",
      "94614038209.12686\n",
      "97082114494.33832\n",
      "95346150341.93028\n",
      "96545255520.97606\n",
      "95706482002.02722\n",
      "96288081054.0665\n",
      "95882336873.30379\n",
      "96164199016.92503\n",
      "95967815792.94357\n",
      "96104361796.16481\n",
      "96009284895.81973\n",
      "96075420996.07306\n",
      "96029384412.82758\n",
      "96061414503.21915\n",
      "96039121992.89536\n",
      "96054633656.38246\n",
      "96043838514.73543\n",
      "96051350404.47896\n",
      "96046122781.71568\n",
      "96049760553.8609\n",
      "96047229022.59155\n",
      "96048990672.40424\n",
      "96047764747.45828\n",
      "96048617852.69061\n",
      "96048024182.54474\n",
      "96048437311.00407\n",
      "96048149818.2545\n",
      "96048349881.5285\n",
      "96048210659.24364\n",
      "96048307542.67422\n",
      "96048240122.37106\n",
      "96048287039.51718\n",
      "96048254390.30655\n",
      "96048277110.58432\n",
      "96048261299.75354\n"
     ]
    }
   ],
   "source": [
    "w=np.random.uniform(0,1,1) #here w is 1d array(lower limit,upperlimit,size)\n",
    "b=np.random.random()\n",
    "yhat=output_neuron(X,w,b)\n",
    "print(loss(yhat,y))\n",
    "print(\"initial parameters:\",w,b)\n",
    "for epoch in range(50):\n",
    "    b,w=update_parameters(X,y,w,b,.002)\n",
    "    yhat=output_neuron(X,w,b)\n",
    "    print(loss(yhat,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([14287.27699295]), 89.93389250770889)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([142962.70382203,  42951.76487137])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_sample=np.array([[10],[3]])\n",
    "output_neuron(new_sample,w,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../../dataset/regression/salary_2_variable.csv')\n",
    "df.Gender=df.Gender.map({'Male':0,'Female':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exp</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1</td>\n",
       "      <td>0</td>\n",
       "      <td>41000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "      <td>36205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>37731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>43525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.2</td>\n",
       "      <td>1</td>\n",
       "      <td>39891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.9</td>\n",
       "      <td>0</td>\n",
       "      <td>56642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>60150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.2</td>\n",
       "      <td>1</td>\n",
       "      <td>56240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.3</td>\n",
       "      <td>0</td>\n",
       "      <td>59150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.8</td>\n",
       "      <td>0</td>\n",
       "      <td>61000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Exp  Gender  Salary\n",
       "0  1.1       0   41000\n",
       "1  1.3       1   36205\n",
       "2  1.5       1   37731\n",
       "3  2.0       0   43525\n",
       "4  2.2       1   39891\n",
       "5  2.9       0   56642\n",
       "6  3.0       0   60150\n",
       "7  3.2       1   56240\n",
       "8  3.3       0   59150\n",
       "9  3.8       0   61000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=df.iloc[:,:-1].values\n",
    "y=df.iloc[:,-1].values\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(X,ytrue,w,b,lr):\n",
    "    bias_derv=np.sum((X@w+b)-ytrue)/len(ytrue)\n",
    "    weight1_derv=np.sum(((X[:,[0]]@w[0].reshape(1,-1)+b)-ytrue)*X[:,[0]])/len(ytrue)\n",
    "    weight2_derv=np.sum(((X[:,[1]]@w[1].reshape(1,-1)+b)-ytrue)*X[:,[1]])/len(ytrue)\n",
    "    \n",
    "    new_bias=b-lr*bias_derv\n",
    "    new_weight1=w[0]-lr*weight1_derv\n",
    "    new_weight2=w[1]-lr*weight2_derv\n",
    "    \n",
    "    return new_bias,np.array([new_weight1,new_weight2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial parameters:\n",
      " [0.34286537 0.27848346] 0.8987953433738299 [1.27594726 1.62300379 1.69157686 1.58452609 1.93158262 1.89310493\n",
      " 1.92739147 2.274448   2.03025108 2.20168377]\n",
      "110247231433.54623\n",
      "31936786970.527023\n",
      "11330829005.254087\n",
      "5775693870.718916\n",
      "4313959451.930315\n",
      "4050199574.9081726\n"
     ]
    }
   ],
   "source": [
    "w=np.random.uniform(0,1,2)\n",
    "b=np.random.random()\n",
    "print(\"initial parameters:\\n\",w,b,output_neuron(X,w,b))\n",
    "for epoch in range(60):\n",
    "    b,w=update_parameters(X,y,w,b,.001)\n",
    "    yhat=output_neuron(X,w,b)\n",
    "    if(epoch%10==0):\n",
    "        print(loss(yhat,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([17278.51360147, 10372.95110476]), 844.5836190436737)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([59591.52986403, 69964.48096879, 97610.10273114, 87237.15162637,\n",
       "       66502.93530461, 57863.67850388])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample=np.array([[3.4,0],[3.4,1],[5,1],[5,0],[3.8,0],[3.3,0]])\n",
    "output_neuron(test_sample,w,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
