{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "clf=cv2.CascadeClassifier('../../dataset/haar/haarcascade_frontalface_default.xml')\n",
    "img_clr=cv2.imread('./deepika-padukone.jpg')\n",
    "img_gray=cv2.cvtColor(img_clr,cv2.COLOR_BGR2GRAY)\n",
    "faces=clf.detectMultiScale(img_gray)\n",
    "for x,y,w,h in faces:\n",
    "    cv2.rectangle(img_clr,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "cv2.imshow('',img_clr)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face and Eyes Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_clf=cv2.CascadeClassifier('../../dataset/haar/haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_clf=cv2.CascadeClassifier('../../dataset/haar/haarcascade_eye.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_clr=cv2.imread('./deepika-padukone.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gray=cv2.cvtColor(img_clr,cv2.COLOR_BGR2GRAY)\n",
    "faces=face_clf.detectMultiScale(img_gray)\n",
    "for x,y,w,h in faces:\n",
    "    cv2.rectangle(img_clr,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "    myface_gray=img_gray[y:y+h,x:x+w]\n",
    "    myface_clr=img_clr[y:y+h,x:x+w]\n",
    "    eyes=eye_clf.detectMultiScale(myface_gray, 1.5)\n",
    "    for ex,ey,ew,eh in eyes:\n",
    "        cv2.rectangle(myface_clr,(ex,ey),(ex+ew,ey+eh),(255,0,0),2)\n",
    "cv2.imshow('',img_clr)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to read video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "vdocap=cv2.VideoCapture('e:/bahubali.mp4')\n",
    "while(True):\n",
    "    flag,img=vdocap.read()\n",
    "    if(flag==False):\n",
    "        break\n",
    "    cv2.imshow('',img)\n",
    "    k=cv2.waitKey(10)\n",
    "    if(k==ord('q')):\n",
    "        break\n",
    "vdocap.release()        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cap = cv2.VideoCapture('e:/video2.avi')\n",
    "car_cascade = cv2.CascadeClassifier('e:/cars.xml')\n",
    "while True:\n",
    "    ret, img = cap.read()\n",
    "    if (type(img) == type(None)):\n",
    "        break   \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    cars = car_cascade.detectMultiScale(gray, 1.3, 1)\n",
    "    for (x,y,w,h) in cars:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),4)    \n",
    "    cv2.imshow('video', img)\n",
    "    if cv2.waitKey(33) == 27:\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reading video using webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "#vdocap=cv2.VideoCapture(0) #intergrated webcam\n",
    "vdocap=cv2.VideoCapture(1) #external webcam\n",
    "while(True):\n",
    "    flag,img=vdocap.read()\n",
    "    if(flag==False):\n",
    "        break\n",
    "    cv2.imshow('',img)\n",
    "    k=cv2.waitKey(10)\n",
    "    if(k==ord('q')):\n",
    "        break\n",
    "vdocap.release()        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face detection in video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "vdocap=cv2.VideoCapture(1) #external webcam\n",
    "clf=cv2.CascadeClassifier('c:/dataset/haar/haarcascade_frontalface_default.xml')\n",
    "while(True):\n",
    "    flag,img_clr=vdocap.read()\n",
    "    if(flag==False):\n",
    "        break\n",
    "    img_gray=cv2.cvtColor(img_clr,cv2.COLOR_BGR2GRAY)\n",
    "    faces=clf.detectMultiScale(img_gray)\n",
    "    for x,y,w,h in faces:\n",
    "        cv2.rectangle(img_clr,(x,y),(x+w,y+h),(0,0,255),2)    \n",
    "    cv2.imshow('',img_clr)\n",
    "    k=cv2.waitKey(1)\n",
    "    if(k==ord('q')):\n",
    "        break\n",
    "vdocap.release()        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "vdocap=cv2.VideoCapture('e:/bahubali.mp4')\n",
    "clf=cv2.CascadeClassifier('c:/dataset/haar/haarcascade_frontalface_default.xml')\n",
    "while(True):\n",
    "    flag,img_clr=vdocap.read()\n",
    "    if(flag==False):\n",
    "        break\n",
    "    img_gray=cv2.cvtColor(img_clr,cv2.COLOR_BGR2GRAY)\n",
    "    faces=clf.detectMultiScale(img_gray,1.5)\n",
    "    for x,y,w,h in faces:\n",
    "        cv2.rectangle(img_clr,(x,y),(x+w,y+h),(0,0,255),2)    \n",
    "    cv2.imshow('',img_clr)\n",
    "    k=cv2.waitKey(1)\n",
    "    if(k==ord('q')):\n",
    "        break\n",
    "vdocap.release()        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating dataset for self face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3600"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "vdocap=cv2.VideoCapture(1) #external webcam\n",
    "clf=cv2.CascadeClassifier('c:/dataset/haar/haarcascade_frontalface_default.xml')\n",
    "i=1\n",
    "while(True):\n",
    "    flag,img_clr=vdocap.read()\n",
    "    if(flag==False):\n",
    "        break\n",
    "    img_gray=cv2.cvtColor(img_clr,cv2.COLOR_BGR2GRAY)\n",
    "    faces=clf.detectMultiScale(img_gray)\n",
    "    for x,y,w,h in faces:\n",
    "        cv2.rectangle(img_clr,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "        myface=img_clr[y:y+h,x:x+w]\n",
    "        cv2.imwrite(f'Aditya/{i}.png',myface)\n",
    "        i+=1\n",
    "    cv2.imshow('',img_clr)\n",
    "    k=cv2.waitKey(1)\n",
    "    if(k==ord('q')):\n",
    "        break\n",
    "vdocap.release()        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data to build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "X=[]\n",
    "y=[]\n",
    "img_list=os.listdir('Aditya')\n",
    "for img in img_list:\n",
    "    gray=cv2.imread(f'Aditya/{img}',cv2.IMREAD_GRAYSCALE)\n",
    "    gray=cv2.resize(gray,(60,60))\n",
    "    X.append(gray.flatten())\n",
    "    y.append('Aditya')\n",
    "img_list=os.listdir('Sachin')\n",
    "for img in img_list:\n",
    "    gray=cv2.imread(f'Sachin/{img}',cv2.IMREAD_GRAYSCALE)\n",
    "    gray=cv2.resize(gray,(60,60))\n",
    "    X.append(gray.flatten())\n",
    "    y.append('Sachin')\n",
    "\n",
    "import numpy as np\n",
    "X_train=np.array(X)\n",
    "y_train=np.array(y)    \n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Aditya', 'Aditya', 'Aditya', 'Aditya', 'Aditya', 'Aditya',\n",
       "       'Aditya', 'Aditya', 'Aditya', 'Aditya', 'Sachin', 'Sachin',\n",
       "       'Sachin', 'Sachin', 'Sachin', 'Sachin', 'Sachin', 'Sachin',\n",
       "       'Sachin', 'Sachin'], dtype='<U6')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 7)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca=PCA(.99)\n",
    "X_train_new=pca.fit_transform(X_train)\n",
    "X_train_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log=LogisticRegression(solver='lbfgs')\n",
    "log.fit(X_train_new,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "vdocap=cv2.VideoCapture(1) #external webcam\n",
    "clf=cv2.CascadeClassifier('c:/dataset/haar/haarcascade_frontalface_default.xml')\n",
    "while(True):\n",
    "    flag,img_clr=vdocap.read()\n",
    "    if(flag==False):\n",
    "        break\n",
    "    img_gray=cv2.cvtColor(img_clr,cv2.COLOR_BGR2GRAY)\n",
    "    faces=clf.detectMultiScale(img_gray)\n",
    "    for x,y,w,h in faces:\n",
    "        cv2.rectangle(img_clr,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "        myface=img_gray[y:y+h,x:x+w]\n",
    "        myface=cv2.resize(myface,(60,60))\n",
    "        myface=myface.reshape(1,3600)\n",
    "        X_test=pca.transform(myface)\n",
    "        pred=log.predict(X_test)\n",
    "        cv2.putText(img_clr,str(pred[0]),(x,y-10),cv2.FONT_HERSHEY_PLAIN,2,(0,0,255),1)\n",
    "    cv2.imshow('',img_clr)\n",
    "    k=cv2.waitKey(1)\n",
    "    if(k==ord('q')):\n",
    "        break\n",
    "vdocap.release()        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
